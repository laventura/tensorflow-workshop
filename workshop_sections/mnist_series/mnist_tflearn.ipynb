{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2016 Google Inc. All Rights Reserved.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "    http://www.apache.org/licenses/LICENSE-2.0\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n",
    "\n",
    "--------------------------------------\n",
    "\n",
    "This notebook is similar in functionality to [this python script](https://github.com/amygdala/tensorflow-workshop/blob/master/workshop_sections/mnist_series/mnist_tflearn.py), and is used with [this README](https://github.com/amygdala/tensorflow-workshop/blob/master/workshop_sections/mnist_series/02_README_mnist_tflearn.md).  It shows how to use TensorFlow's high-level apis, in `contrib.tflearn`, to easily build a classifier with multiple hidden layers.\n",
    "\n",
    "First, do some imports and set some variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./the_hard_way/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ./the_hard_way/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./the_hard_way/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./the_hard_way/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "DATA_DIR = \"./the_hard_way/MNIST_data\"\n",
    "\n",
    "# read in data, downloading first as necessary\n",
    "DATA_SETS = input_data.read_data_sets(DATA_DIR)\n",
    "\n",
    "# comment out for less info during the training runs.\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "# define a utility function for generating a new directory in which to save \n",
    "# model information, so multiple training runs don't stomp on each other.\n",
    "def getNewPath(base=\"/tmp/tfmodels/mnist_tflearn\"):\n",
    "    logpath = os.path.join(base, str(int(time.time())))\n",
    "    print(\"Logging to {}\".format(logpath))\n",
    "    return logpath\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll first define a function that adds a LinearClassifier and runs its `fit()` method, which will train the model. Note that we didn't need to explicitly define a model graph or a training loop ourselves.  \n",
    "\n",
    "Once we've trained the model, we run the `evaluate()` method, which uses the trained model. To do this, it loads the most recent checkpointed model info available.  The model checkpoint(s) will be generated during the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def define_and_run_linear_classifier(num_steps, logdir):\n",
    "    \"\"\"Run a linear classifier.\"\"\"\n",
    "    global DATA_SETS\n",
    "    feature_columns = tf.contrib.learn.infer_real_valued_columns_from_input(\n",
    "        DATA_SETS.train.images)\n",
    "    classifier = tf.contrib.learn.LinearClassifier(\n",
    "                feature_columns=feature_columns, \n",
    "                n_classes=10,\n",
    "               model_dir=logdir\n",
    "                )\n",
    "    classifier.fit(DATA_SETS.train.images,\n",
    "                   DATA_SETS.train.labels.astype(numpy.int64),\n",
    "                   batch_size=100, steps=num_steps\n",
    "                  )\n",
    "    print(\"Finished training.\")\n",
    "    # Evaluate accuracy.\n",
    "    accuracy_score = classifier.evaluate(\n",
    "        DATA_SETS.test.images,\n",
    "        DATA_SETS.test.labels.astype(numpy.int64))['accuracy']\n",
    "    print('Linear Classifier Accuracy: {0:f}'.format(accuracy_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, add a function that defines a `DNNClassifier`, and runs its `fit()` method, which will train the model. Again note that we didn't need to explicitly define a model graph or a training loop ourselves.  \n",
    "\n",
    "Then after we've trained the model, we run the classifier's `evaluate()` method, which uses the trained model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def define_and_run_dnn_classifier(num_steps, logdir, lr=0.1):\n",
    "    \"\"\"Run a DNN classifier.\"\"\"\n",
    "    feature_columns = tf.contrib.learn.infer_real_valued_columns_from_input(DATA_SETS.train.images)\n",
    "    \n",
    "    classifier = tf.contrib.learn.DNNClassifier(\n",
    "        feature_columns=feature_columns, \n",
    "        n_classes=10,\n",
    "        hidden_units=[128, 32],\n",
    "        # After you've done a training run with optimizer learning rate 0.1,\n",
    "        # change it to 0.5 and run the training again.  Use TensorBoard to take\n",
    "        # a look at the difference.  You can see both runs by pointing it to the\n",
    "        # parent model directory, which by default is:\n",
    "        #   tensorboard --logdir=/tmp/tfmodels/mnist_tflearn\n",
    "        optimizer=tf.train.ProximalAdagradOptimizer(learning_rate=lr),\n",
    "        model_dir=logdir\n",
    "        )\n",
    "    classifier.fit(DATA_SETS.train.images,\n",
    "                   DATA_SETS.train.labels.astype(numpy.int64),\n",
    "                   batch_size=100, max_steps=num_steps)\n",
    "    print(\"Finished running the training via the fit() method\")\n",
    "    \n",
    "    accuracy_score = classifier.evaluate(\n",
    "        DATA_SETS.test.images,\n",
    "        DATA_SETS.test.labels.astype(numpy.int64))['accuracy']\n",
    "    print('DNN Classifier Accuracy: {0:f}'.format(accuracy_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can call the functions that define and train our classifiers.  Let's start with the LinearClassifier, which won't be very accurate. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Change warning: default value of `enable_centered_bias` will change after 2016-10-09. It will be disabled by default.Instructions for keeping existing behaviour:\n",
      "Explicitly set `enable_centered_bias` to 'True' if you want to keep existing behaviour.\n",
      "WARNING:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'save_checkpoints_secs': 600, 'save_summary_steps': 100, 'tf_random_seed': None, '_job_name': None, 'cluster_spec': None, 'keep_checkpoint_max': 5, 'keep_checkpoint_every_n_hours': 10000, 'num_ps_replicas': 0, 'evaluation_master': '', 'task': 0, 'tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_is_chief': True, 'master': ''}\n",
      "INFO:tensorflow:Setting feature info to TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(784)]), is_sparse=False)\n",
      "INFO:tensorflow:Setting targets info to TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False)\n",
      "WARNING:tensorflow:tf.variable_op_scope(values, name, default_name) is deprecated, use tf.variable_scope(name, default_name, values)\n",
      "INFO:tensorflow:Transforming feature_column _RealValuedColumn(column_name='', dimension=784, default_value=None, dtype=tf.float32, normalizer=None)\n",
      "INFO:tensorflow:Create CheckpointSaverHook\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Linear classifier ...\n",
      "Logging to /tmp/tfmodels/mnist_tflearn/1481183342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.30259, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tfmodels/mnist_tflearn/1481183342/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.391843, step = 101\n",
      "INFO:tensorflow:loss = 0.304103, step = 201\n",
      "INFO:tensorflow:loss = 0.380147, step = 301\n",
      "INFO:tensorflow:loss = 0.429173, step = 401\n",
      "INFO:tensorflow:loss = 0.33165, step = 501\n",
      "INFO:tensorflow:loss = 0.175632, step = 601\n",
      "INFO:tensorflow:loss = 0.282347, step = 701\n",
      "INFO:tensorflow:loss = 0.259106, step = 801\n",
      "INFO:tensorflow:loss = 0.292558, step = 901\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tfmodels/mnist_tflearn/1481183342/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.240117.\n",
      "WARNING:tensorflow:Given features: Tensor(\"input:0\", shape=(?, 784), dtype=float32), required signatures: TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(784)]), is_sparse=False).\n",
      "WARNING:tensorflow:Given targets: Tensor(\"output:0\", shape=(?,), dtype=int64), required signatures: TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False).\n",
      "WARNING:tensorflow:tf.variable_op_scope(values, name, default_name) is deprecated, use tf.variable_scope(name, default_name, values)\n",
      "INFO:tensorflow:Transforming feature_column _RealValuedColumn(column_name='', dimension=784, default_value=None, dtype=tf.float32, normalizer=None)\n",
      "INFO:tensorflow:Restored model from /tmp/tfmodels/mnist_tflearn/1481183342\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 1000.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for 1000 step: accuracy = 0.9218, loss = 0.283391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Classifier Accuracy: 0.921800\n"
     ]
    }
   ],
   "source": [
    "print(\"Running Linear classifier ...\")\n",
    "define_and_run_linear_classifier(1000, getNewPath())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's run the DNN Classifier.  First, let's try it with a .1 learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Change warning: default value of `enable_centered_bias` will change after 2016-10-09. It will be disabled by default.Instructions for keeping existing behaviour:\n",
      "Explicitly set `enable_centered_bias` to 'True' if you want to keep existing behaviour.\n",
      "WARNING:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'save_checkpoints_secs': 600, 'save_summary_steps': 100, 'tf_random_seed': None, '_job_name': None, 'cluster_spec': None, 'keep_checkpoint_max': 5, 'keep_checkpoint_every_n_hours': 10000, 'num_ps_replicas': 0, 'evaluation_master': '', 'task': 0, 'tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_is_chief': True, 'master': ''}\n",
      "INFO:tensorflow:Setting feature info to TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(784)]), is_sparse=False)\n",
      "INFO:tensorflow:Setting targets info to TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False)\n",
      "INFO:tensorflow:Transforming feature_column _RealValuedColumn(column_name='', dimension=784, default_value=None, dtype=tf.float32, normalizer=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running DNN classifier with .1 learning rate...\n",
      "Logging to /tmp/tfmodels/mnist_tflearn/1481183417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:load_variable (from tensorflow.contrib.learn.python.learn.utils.checkpoints) is deprecated and will be removed after 2016-08-22.\n",
      "Instructions for updating:\n",
      "Please use tf.contrib.framework.load_variable instead\n",
      "INFO:tensorflow:Create CheckpointSaverHook\n",
      "INFO:tensorflow:loss = 2.37413, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tfmodels/mnist_tflearn/1481183417/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.333397, step = 101\n",
      "INFO:tensorflow:loss = 0.293119, step = 201\n",
      "INFO:tensorflow:loss = 0.249066, step = 301\n",
      "INFO:tensorflow:loss = 0.173243, step = 401\n",
      "INFO:tensorflow:loss = 0.186846, step = 501\n",
      "INFO:tensorflow:loss = 0.0889015, step = 601\n",
      "INFO:tensorflow:loss = 0.0852823, step = 701\n",
      "INFO:tensorflow:loss = 0.122428, step = 801\n",
      "INFO:tensorflow:loss = 0.081551, step = 901\n",
      "INFO:tensorflow:loss = 0.0973008, step = 1001\n",
      "INFO:tensorflow:loss = 0.134592, step = 1101\n",
      "INFO:tensorflow:loss = 0.0369817, step = 1201\n",
      "INFO:tensorflow:loss = 0.0427609, step = 1301\n",
      "INFO:tensorflow:loss = 0.0393555, step = 1401\n",
      "INFO:tensorflow:loss = 0.0423736, step = 1501\n",
      "INFO:tensorflow:loss = 0.0543201, step = 1601\n",
      "INFO:tensorflow:loss = 0.153698, step = 1701\n",
      "INFO:tensorflow:loss = 0.0918153, step = 1801\n",
      "INFO:tensorflow:loss = 0.00967422, step = 1901\n",
      "INFO:tensorflow:loss = 0.138341, step = 2001\n",
      "INFO:tensorflow:loss = 0.0924325, step = 2101\n",
      "INFO:tensorflow:loss = 0.0690881, step = 2201\n",
      "INFO:tensorflow:loss = 0.0684812, step = 2301\n",
      "INFO:tensorflow:loss = 0.128247, step = 2401\n",
      "INFO:tensorflow:loss = 0.0666748, step = 2501\n",
      "INFO:tensorflow:loss = 0.0756833, step = 2601\n",
      "INFO:tensorflow:loss = 0.036042, step = 2701\n",
      "INFO:tensorflow:loss = 0.0629272, step = 2801\n",
      "INFO:tensorflow:loss = 0.0240231, step = 2901\n",
      "INFO:tensorflow:loss = 0.0942761, step = 3001\n",
      "INFO:tensorflow:loss = 0.0612956, step = 3101\n",
      "INFO:tensorflow:loss = 0.0294327, step = 3201\n",
      "INFO:tensorflow:loss = 0.0315644, step = 3301\n",
      "INFO:tensorflow:loss = 0.0337366, step = 3401\n",
      "INFO:tensorflow:loss = 0.0324139, step = 3501\n",
      "INFO:tensorflow:loss = 0.0364014, step = 3601\n",
      "INFO:tensorflow:loss = 0.024071, step = 3701\n",
      "INFO:tensorflow:loss = 0.0747708, step = 3801\n",
      "INFO:tensorflow:loss = 0.00520732, step = 3901\n",
      "INFO:tensorflow:loss = 0.00379923, step = 4001\n",
      "INFO:tensorflow:loss = 0.0373037, step = 4101\n",
      "INFO:tensorflow:loss = 0.0112747, step = 4201\n",
      "INFO:tensorflow:loss = 0.00673397, step = 4301\n",
      "INFO:tensorflow:loss = 0.0193415, step = 4401\n",
      "INFO:tensorflow:loss = 0.0147208, step = 4501\n",
      "INFO:tensorflow:loss = 0.0211748, step = 4601\n",
      "INFO:tensorflow:loss = 0.0326647, step = 4701\n",
      "INFO:tensorflow:loss = 0.0441994, step = 4801\n",
      "INFO:tensorflow:loss = 0.00226999, step = 4901\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/tfmodels/mnist_tflearn/1481183417/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0119818.\n",
      "WARNING:tensorflow:Given features: Tensor(\"input:0\", shape=(?, 784), dtype=float32), required signatures: TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(784)]), is_sparse=False).\n",
      "WARNING:tensorflow:Given targets: Tensor(\"output:0\", shape=(?,), dtype=int64), required signatures: TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False).\n",
      "INFO:tensorflow:Transforming feature_column _RealValuedColumn(column_name='', dimension=784, default_value=None, dtype=tf.float32, normalizer=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished running the training via the fit() method\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restored model from /tmp/tfmodels/mnist_tflearn/1481183417\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 5000.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for 5000 step: accuracy = 0.9784, loss = 0.0700139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNN Classifier Accuracy: 0.978400\n"
     ]
    }
   ],
   "source": [
    "print(\"Running DNN classifier with .1 learning rate...\")\n",
    "classifier = define_and_run_dnn_classifier(5000, getNewPath(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's run it with a .5 learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Change warning: default value of `enable_centered_bias` will change after 2016-10-09. It will be disabled by default.Instructions for keeping existing behaviour:\n",
      "Explicitly set `enable_centered_bias` to 'True' if you want to keep existing behaviour.\n",
      "WARNING:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'save_checkpoints_secs': 600, 'save_summary_steps': 100, 'tf_random_seed': None, '_job_name': None, 'cluster_spec': None, 'keep_checkpoint_max': 5, 'keep_checkpoint_every_n_hours': 10000, 'num_ps_replicas': 0, 'evaluation_master': '', 'task': 0, 'tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_is_chief': True, 'master': ''}\n",
      "INFO:tensorflow:Setting feature info to TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(784)]), is_sparse=False)\n",
      "INFO:tensorflow:Setting targets info to TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False)\n",
      "INFO:tensorflow:Transforming feature_column _RealValuedColumn(column_name='', dimension=784, default_value=None, dtype=tf.float32, normalizer=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running DNN classifier with .1 learning rate...\n",
      "Logging to /tmp/tfmodels/mnist_tflearn/1481183497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:load_variable (from tensorflow.contrib.learn.python.learn.utils.checkpoints) is deprecated and will be removed after 2016-08-22.\n",
      "Instructions for updating:\n",
      "Please use tf.contrib.framework.load_variable instead\n",
      "INFO:tensorflow:Create CheckpointSaverHook\n",
      "INFO:tensorflow:loss = 2.33871, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tfmodels/mnist_tflearn/1481183497/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.90681, step = 101\n",
      "INFO:tensorflow:loss = 1.58743, step = 201\n",
      "INFO:tensorflow:loss = 1.38492, step = 301\n",
      "INFO:tensorflow:loss = 0.98334, step = 401\n",
      "INFO:tensorflow:loss = 0.824214, step = 501\n",
      "INFO:tensorflow:loss = 0.380703, step = 601\n",
      "INFO:tensorflow:loss = 0.46079, step = 701\n",
      "INFO:tensorflow:loss = 0.300015, step = 801\n",
      "INFO:tensorflow:loss = 0.230406, step = 901\n",
      "INFO:tensorflow:loss = 0.339944, step = 1001\n",
      "INFO:tensorflow:loss = 0.398754, step = 1101\n",
      "INFO:tensorflow:loss = 0.319462, step = 1201\n",
      "INFO:tensorflow:loss = 0.110461, step = 1301\n",
      "INFO:tensorflow:loss = 0.252838, step = 1401\n",
      "INFO:tensorflow:loss = 0.176851, step = 1501\n",
      "INFO:tensorflow:loss = 0.18334, step = 1601\n",
      "INFO:tensorflow:loss = 0.705764, step = 1701\n",
      "INFO:tensorflow:loss = 0.251366, step = 1801\n",
      "INFO:tensorflow:loss = 0.07945, step = 1901\n",
      "INFO:tensorflow:loss = 0.377145, step = 2001\n",
      "INFO:tensorflow:loss = 0.0869918, step = 2101\n",
      "INFO:tensorflow:loss = 0.150349, step = 2201\n",
      "INFO:tensorflow:loss = 0.194337, step = 2301\n",
      "INFO:tensorflow:loss = 0.219885, step = 2401\n",
      "INFO:tensorflow:loss = 0.197969, step = 2501\n",
      "INFO:tensorflow:loss = 0.151745, step = 2601\n",
      "INFO:tensorflow:loss = 0.204721, step = 2701\n",
      "INFO:tensorflow:loss = 0.113117, step = 2801\n",
      "INFO:tensorflow:loss = 0.0681607, step = 2901\n",
      "INFO:tensorflow:loss = 0.207346, step = 3001\n",
      "INFO:tensorflow:loss = 0.114014, step = 3101\n",
      "INFO:tensorflow:loss = 0.0954872, step = 3201\n",
      "INFO:tensorflow:loss = 0.097144, step = 3301\n",
      "INFO:tensorflow:loss = 0.200259, step = 3401\n",
      "INFO:tensorflow:loss = 0.126197, step = 3501\n",
      "INFO:tensorflow:loss = 0.180605, step = 3601\n",
      "INFO:tensorflow:loss = 0.122209, step = 3701\n",
      "INFO:tensorflow:loss = 0.216594, step = 3801\n",
      "INFO:tensorflow:loss = 0.0906103, step = 3901\n",
      "INFO:tensorflow:loss = 0.136594, step = 4001\n",
      "INFO:tensorflow:loss = 0.207024, step = 4101\n",
      "INFO:tensorflow:loss = 0.0915224, step = 4201\n",
      "INFO:tensorflow:loss = 0.0535699, step = 4301\n",
      "INFO:tensorflow:loss = 0.145829, step = 4401\n",
      "INFO:tensorflow:loss = 0.0938965, step = 4501\n",
      "INFO:tensorflow:loss = 0.146574, step = 4601\n",
      "INFO:tensorflow:loss = 0.15986, step = 4701\n",
      "INFO:tensorflow:loss = 0.133367, step = 4801\n",
      "INFO:tensorflow:loss = 0.021194, step = 4901\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/tfmodels/mnist_tflearn/1481183497/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0804689.\n",
      "WARNING:tensorflow:Given features: Tensor(\"input:0\", shape=(?, 784), dtype=float32), required signatures: TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(784)]), is_sparse=False).\n",
      "WARNING:tensorflow:Given targets: Tensor(\"output:0\", shape=(?,), dtype=int64), required signatures: TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False).\n",
      "INFO:tensorflow:Transforming feature_column _RealValuedColumn(column_name='', dimension=784, default_value=None, dtype=tf.float32, normalizer=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished running the training via the fit() method\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restored model from /tmp/tfmodels/mnist_tflearn/1481183497\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 5000.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for 5000 step: accuracy = 0.9584, loss = 0.146584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNN Classifier Accuracy: 0.958400\n"
     ]
    }
   ],
   "source": [
    "print(\"Running DNN classifier with .1 learning rate...\")\n",
    "classifier = define_and_run_dnn_classifier(5000, getNewPath(), lr=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare your results, start up TensorBoard as follows in a new terminal window. (If you get a 'not found' error, make sure you've activated your virtual environment in that new window):\n",
    "\n",
    "```sh\n",
    "$ tensorboard --logdir=/tmp/tfmodels/mnist_tflearn\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
